name: ğŸš€ 2026 Ultimate Hyper-Speed System (Parallel Unlocked)

on:
  push:
    branches: [ "main", "master" ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ "main", "master" ]
  workflow_call:
    inputs:
      data_count:
        description: 'Callerë¡œë¶€í„° ì „ë‹¬ë°›ì„ ë°ì´í„° ìˆ˜'
        required: false
        default: '500000'
        type: string
  workflow_dispatch:
    inputs:
      data_count:
        description: 'ìƒì„±í•  ë°ì´í„° í–‰ ìˆ˜ (ê¸°ë³¸: 1,000,000)'
        required: true
        default: '1000000'
        type: string

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  PYTHONIOENCODING: "utf-8"
  DATA_COUNT: ${{ inputs.data_count || '1000000' }}

permissions:
  contents: write
  packages: write
  actions: write

jobs:
  # ==================================================================================
  # JOB 1: ì´ˆê³ ì† ë³‘ë ¬ ë¹Œë“œ & ë°ì´í„° ìƒì„± (ì¶©ëŒ ë°©ì§€ ë° ìì› í™•ë³´ ì•„í‚¤í…ì²˜)
  # ==================================================================================
  managed-build:
    name: âš¡ Hyper-Build on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    # [CRITICAL] íƒ€ì„ì•„ì›ƒì„ ìµœëŒ€ì¹˜(360ë¶„=6ì‹œê°„)ë¡œ ì„¤ì •í•˜ì—¬ ê°•ì œ ì¢…ë£Œ ë°©ì§€
    timeout-minutes: 360
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
    defaults:
      run:
        shell: bash
    steps:
    - name: ğŸ“‚ Checkout Repository
      uses: actions/checkout@v4

    # [Resource] ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë””ìŠ¤í¬ ì •ë¦¬ ë° Swap ë©”ëª¨ë¦¬ ìƒì„± (Linux Only)
    - name: ğŸ§¹ Free Disk Space & Create Swap (Prevention of OOM)
      if: matrix.os == 'ubuntu-latest'
      run: |
        echo "::: Cleaning Disk Space for Massive Data :::"
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /opt/ghc
        
        echo "::: Creating 7GB Swap File :::"
        sudo fallocate -l 7G /swapfile
        sudo chmod 600 /swapfile
        sudo mkswap /swapfile
        sudo swapon /swapfile
        df -h
        free -h

    - name: âš™ï¸ Set Dynamic Environment
      run: |
        RUN_ID="${{ github.run_id }}"
        if [[ "${{ matrix.os }}" == "ubuntu-latest" ]]; then
          echo "ARTIFACT_NAME=Binary-Linux-${RUN_ID}" >> $GITHUB_ENV
          echo "OS_TYPE=Linux" >> $GITHUB_ENV
        else
          echo "ARTIFACT_NAME=Binary-Windows-${RUN_ID}" >> $GITHUB_ENV
          echo "OS_TYPE=Windows" >> $GITHUB_ENV
        fi
        echo "âœ… Dynamic Isolation ID: $RUN_ID"

    - name: ğŸ› ï¸ Setup Optimization Tools
      run: |
        echo "::: Initializing High-Performance Env for $OS_TYPE :::"
        if [[ "$OS_TYPE" == "Linux" ]]; then
          sudo apt-get update
          sudo apt-get install -y build-essential cmake cppcheck tree g++ ccache
          echo "PATH=/usr/lib/ccache:$PATH" >> $GITHUB_ENV
        else
          choco install cppcheck -y --no-progress
        fi

    - name: ğŸ Setup Python 3.12 with Cache
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'

    - name: ğŸ“¦ Install Python Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install Pillow qrcode pandas matplotlib

    - name: âš¡ Restore Compiler Cache
      if: runner.os == 'Linux'
      uses: actions/cache@v4
      with:
        path: ~/.cache/ccache
        key: ${{ runner.os }}-ccache-${{ github.ref_name }}
        restore-keys: |
          ${{ runner.os }}-ccache-

    # ----------------------------------------------------------------
    # 4. [Core] Upgrade Manager: ë©”ëª¨ë¦¬ ì•ˆì „ ì„¤ê³„ ë° Heartbeat ì¶”ê°€
    # ----------------------------------------------------------------
    - name: ğŸ“ Generate Optimized Upgrade Manager
      run: |
        cat <<'EOF' > upgrade_manager.py
        import os
        import sys
        
        SYSTEM_VERSION = "2026.4.0 (Anti-Crash Edition)"
        GCC_FLAGS = "-O3 -Wall -Wextra -std=c++20 -pthread -march=native"
        
        def log(msg):
            try: print(f"[âš™ï¸ MANAGER] {msg}")
            except: pass
        
        def generate_cpp_source():
            log(f"Generating Optimized C++20 Source (v{SYSTEM_VERSION})...")
            
            content = """
        #include <iostream>
        #include <fstream>
        #include <filesystem>
        #include <vector>
        #include <string>
        #include <thread>
        #include <future>
        #include <random>
        #include <iomanip>
        
        namespace fs = std::filesystem;
        
        long long get_target_count() {
            const char* env_p = std::getenv("DATA_COUNT");
            if(env_p) return std::stoll(env_p);
            return 100000;
        }
        
        void optimizeIO() {
            std::ios_base::sync_with_stdio(false);
            std::cin.tie(NULL);
        }
        
        // --- Optimized Data Managers (Heap Allocation for Safety) ---
        class VirtualAccountManager {
        public:
            static void generate(long long count) {
                std::ofstream file("output/data/va_dump.csv");
                // [FIX] Stack Overflow ë°©ì§€ë¥¼ ìœ„í•´ std::vector(Heap) ì‚¬ìš©
                std::vector<char> buffer(2 * 1024 * 1024); // 2MB Buffer
                file.rdbuf()->pubsetbuf(buffer.data(), buffer.size());
                
                file << "Bank,Account,Holder,Balance,Status,RiskScore\\n";
                for(long long i=0; i<count; ++i) {
                    file << (i%2==0 ? "KB-2026" : "WOORI-2026") << ","
                         << "562-" << std::setw(8) << std::setfill('0') << i << ","
                         << "User_" << i << ","
                         << (i * 1500) << ","
                         << (i%10==0 ? "Inactive" : "Active") << ","
                         << (i%100) 
                         << "\\n";
                    
                    // [HEARTBEAT] ë¡œê·¸ ì¹¨ë¬µ ë°©ì§€ (10ë§Œ ê±´ë§ˆë‹¤ ì  ì¶œë ¥)
                    if (i % 100000 == 0) {
                        std::cout << "." << std::flush;
                    }
                }
                std::cout << "\\nâœ… Accounts Generated: " << count << std::endl;
            }
        };
        
        class VirtualCardManager {
        public:
            static void generate(long long count) {
                std::ofstream file("output/data/card_dump.csv");
                std::vector<char> buffer(2 * 1024 * 1024);
                file.rdbuf()->pubsetbuf(buffer.data(), buffer.size());
                
                file << "CardNum,CVC,Expiry,Type,Limit\\n";
                for(long long i=0; i<count; ++i) {
                    file << "4222-" << (2026 + i%5) << "-" << std::setw(4) << std::setfill('0') << i%10000 << "-XXXX,"
                         << (i%999) << ",12/30,"
                         << (i%3==0 ? "VISA" : (i%3==1 ? "MASTER" : "AMEX")) << ","
                         << (5000 + (i%10)*1000)
                         << "\\n";
                         
                    if (i % 100000 == 0) {
                        std::cout << "+" << std::flush;
                    }
                }
                std::cout << "\\nâœ… Cards Generated: " << count << std::endl;
            }
        };
        
        int main(int argc, char* argv[]) {
            optimizeIO();
            fs::create_directories("output/data");
            
            long long target = get_target_count();
            std::cout << "ğŸš€ Starting Parallel Engine v{SYSTEM_VERSION} (Target: " << target << ")..." << std::endl;
            
            // Async Execution with Exception Handling
            try {
                auto f1 = std::async(std::launch::async, VirtualAccountManager::generate, target);
                auto f2 = std::async(std::launch::async, VirtualCardManager::generate, target);
                
                f1.get(); 
                f2.get();
            } catch (const std::exception& e) {
                std::cerr << "CRITICAL ERROR: " << e.what() << std::endl;
                return 1;
            }
            
            std::cout << "âœ¨ Data Generation Completed Successfully." << std::endl;
            return 0;
        }
            """
            final_content = content.replace("{SYSTEM_VERSION}", SYSTEM_VERSION)
            with open("enterprise_main.cpp", "w", encoding="utf-8") as f:
                f.write(final_content.strip())
        
        def generate_build_files():
            log("Generating Build Systems...")
            makefile_content = f"""
        CXX = ccache g++
        CXXFLAGS = {GCC_FLAGS}
        TARGET = server_app_core
        SRCS = enterprise_main.cpp
        
        all: $(TARGET)
        
        $(TARGET): $(SRCS)
        \t$(CXX) $(CXXFLAGS) $(SRCS) -o $(TARGET)
        
        clean:
        \trm -f $(TARGET)
            """
            with open("Makefile", "w", encoding="utf-8") as f: f.write(makefile_content.strip())
            
            cmake = """
        cmake_minimum_required(VERSION 3.15)
        project(MassiveServer2026)
        set(CMAKE_CXX_STANDARD 20)
        
        add_executable(enterprise_main enterprise_main.cpp)
        
        if(UNIX)
            add_compile_options(-O3 -Wall -Wextra -pthread -march=native)
        endif()
        """
            with open("CMakeLists.txt", "w", encoding="utf-8") as f: f.write(cmake.strip())
        
        if __name__ == "__main__":
            generate_cpp_source()
            generate_build_files()
            log("âœ… Optimization Applied.")
        EOF

    - name: ğŸ”„ Execute Upgrade Manager
      run: python upgrade_manager.py

    - name: ğŸ’¥ Build & Run (Parallel Safe)
      run: |
        mkdir -p output_data/data
        
        if [[ "$OS_TYPE" == "Linux" ]]; then
          make -j$(nproc) all
          chmod +x server_app_core
          cp server_app_core final_binary
          echo "::: Executing Binary (Max Timeout Protected) :::"
          ./server_app_core
        else
          mkdir -p build
          cd build
          cmake ..
          cmake --build . --config Release --parallel
          cd ..
          cp build/Release/enterprise_main.exe final_binary.exe
          ./build/Release/enterprise_main.exe
        fi
        
        if [ -d "output" ]; then cp -r output/* output_data/; fi

    - name: ğŸ“Š Generate Report
      run: |
        cat <<'EOF' > gen_report.py
        import os
        with open("output_data/report.html", "w") as f: f.write("<h1>Done</h1>")
        EOF
        python gen_report.py

    - name: ğŸ Finalize
      run: |
        if [[ "$OS_TYPE" == "Linux" ]]; then sha256sum final_binary > checksum.sha256; else sha256sum final_binary.exe > checksum.sha256; fi

    - uses: actions/upload-artifact@v4
      with:
        name: ${{ env.ARTIFACT_NAME }}
        path: |
          final_binary*
          checksum.sha256
          output_data/

  # ==================================================================================
  # JOB 2: Docker ë¹Œë“œ (ë³‘ë ¬ ì‹¤í–‰ ì‹œ íƒœê·¸ ì¶©ëŒ ë°©ì§€)
  # ==================================================================================
  docker-publish:
    name: ğŸ³ Dockerize
    needs: managed-build
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/download-artifact@v4
        with:
          name: Binary-Linux-${{ github.run_id }}

      - name: âš™ï¸ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: ğŸ”¨ Build Docker Context
        run: |
          cat <<EOF > Dockerfile
          FROM ubuntu:24.04
          WORKDIR /app
          COPY final_binary /app/server_app
          COPY output_data /app/data
          RUN chmod +x /app/server_app
          CMD ["./server_app"]
          EOF

      - uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ghcr.io/${{ github.repository }}:${{ github.run_number }}
            ghcr.io/${{ github.repository }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # ==================================================================================
  # JOB 3: í†µí•© ë¦´ë¦¬ì¦ˆ (ë³‘ë ¬ ì•ˆì „ ëª¨ë“œ)
  # ==================================================================================
  release-manager:
    name: ğŸ“¦ Managed Release V3
    needs: [managed-build, docker-publish]
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: write
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: Binary-Linux-${{ github.run_id }}
          path: linux_pkg

      - uses: actions/download-artifact@v4
        with:
          name: Binary-Windows-${{ github.run_id }}
          path: windows_pkg

      - name: ğŸ“¦ Create Release Package
        run: |
          mkdir release_assets
          cp windows_pkg/final_binary.exe release_assets/server_app_2026.exe
          cp linux_pkg/final_binary release_assets/server_app_linux_2026
          cp -r linux_pkg/output_data release_assets/dataset_2026
          cd release_assets
          zip -r ../parallel_system_v${{ github.run_number }}.zip .

      - uses: softprops/action-gh-release@v2
        if: github.ref == 'refs/heads/main'
        with:
          tag_name: v2026.3.0.${{ github.run_number }}
          name: ğŸš€ Parallel System v${{ github.run_number }} (Unlocked)
          body: |
            ## ğŸš€ 2026 Parallel Execution Update
            
            This release enables **Concurrent Workflow Execution**.
            
            ### ğŸ”“ Unlocked Features
            - **Non-Blocking:** Multiple workflows can run simultaneously without waiting.
            - **Workflow Call:** Can be triggered by other pipelines as a submodule.
            - **Isolated Artifacts:** Uses `${{ github.run_id }}` to prevent file collisions.
            
            ğŸ‘‰ **Managed by 2026 Ultimate Pipeline**
          files: parallel_system_v${{ github.run_number }}.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
