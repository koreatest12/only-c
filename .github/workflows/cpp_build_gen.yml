name: Enterprise CI/CD (Large Scale 1MB+)

on:
  push:
    branches: [ "main", "master" ]
  pull_request:
    branches: [ "main", "master" ]
  workflow_dispatch:

permissions:
  contents: write
  packages: write
  actions: write

jobs:
  build-test-generate:
    name: Build & Test on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]

    defaults:
      run:
        shell: bash

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    # 1. í™˜ê²½ë³„ ì˜ì¡´ì„± ì„¤ì¹˜
    - name: Install Dependencies
      if: runner.os == 'Linux'
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential cmake cppcheck tree

    # 2. ëŒ€ê·œëª¨(1MB+) ì†ŒìŠ¤ì½”ë“œ ë° CMakeLists ìƒì„±
    - name: Generate Large Scale Source Code
      run: |
        echo "ğŸ“ Generating Heavy Source Code..."
        
        # [CMake ì„¤ì •]
        cat <<EOF > CMakeLists.txt
        cmake_minimum_required(VERSION 3.10)
        project(EnterpriseServer)
        set(CMAKE_CXX_STANDARD 17)
        set(CMAKE_CXX_STANDARD_REQUIRED True)
        add_executable(enterprise_main enterprise_main.cpp)
        if(WIN32)
            set_target_properties(enterprise_main PROPERTIES OUTPUT_NAME "enterprise_main")
        endif()
        EOF

        # [C++ ì†ŒìŠ¤ì½”ë“œ: ëŒ€ëŸ‰ ë°ì´í„° ë¡œì§ í¬í•¨]
        cat <<EOF > enterprise_main.cpp
        #include <iostream>
        #include <fstream>
        #include <filesystem>
        #include <vector>
        #include <string>
        #include <cassert>
        #include <chrono>
        #include <thread>
        #include <random>

        namespace fs = std::filesystem;

        std::string getCurrentTime() {
            time_t now = time(0);
            char buf[80];
            strftime(buf, sizeof(buf), "%Y-%m-%d %H:%M:%S", localtime(&now));
            return std::string(buf);
        }

        // [ê¸°ëŠ¥ 0] ë°”ì´ë„ˆë¦¬ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•œ ë”ë¯¸ í˜ì´ë¡œë“œ
        class LargePayload {
        public:
            static void loadDummyData() {
                // ì‹¤í–‰ íŒŒì¼ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´ ì •ì  ë¬¸ìì—´ ë°°ì—´ ì‚¬ìš©
                static const std::string heavyData[] = {
                    "Systems_Initialization_Sequence_Alpha_Beta_Gamma_Delta",
                    "Security_Protocol_Override_Authorization_Key_X99283",
                    "Database_Migration_Wizard_v2024_Enterprise_Edition",
                    "Network_Latency_Optimization_Algorithm_Reference_Block"
                };
                // ì»´íŒŒì¼ëŸ¬ ìµœì í™” ë°©ì§€ìš© ì¶œë ¥
                std::cout << "   [System] Loaded Payload: " << heavyData[0].length() << " bytes." << std::endl;
            }
        };

        // [ê¸°ëŠ¥ 1] ëŒ€ëŸ‰ ë°ì´í„° ìƒì„± ì„œë¹„ìŠ¤ (Massive Data Service)
        // ëª©í‘œ: CSV íŒŒì¼ í¬ê¸° 10MB ì´ìƒ
        class BigDataManager {
        public:
            static void generateMassiveTransactions() {
                // 300,000ê±´ ìƒì„± (ì•½ 15MB~20MB ì˜ˆìƒ)
                const int RECORD_COUNT = 300000; 
                std::cout << "ğŸ“Š [Data Service] Generating " << RECORD_COUNT << " massive records (Target > 10MB)..." << std::endl;
                
                fs::create_directories("output/data");
                std::ofstream file("output/data/mass_transactions_large.csv");
                
                // í—¤ë” ì‘ì„±
                file << "TransactionID,UserID,Amount,Type,Currency,Region,Timestamp,VerificationHash,Notes" << std::endl;
                
                for(int i=0; i < RECORD_COUNT; ++i) {
                    file << "TXN_" << (10000000 + i) << ","
                         << "USR_" << (i % 5000) << "," 
                         << (i * 15.5) << ","
                         << (i % 2 == 0 ? "DEPOSIT" : "WITHDRAWAL") << ","
                         << "USD,"
                         << "KR-SEOUL-REGION-01," 
                         << getCurrentTime() << ","
                         << "sha256_hash_value_example_" << i << ","
                         << "User note details for transaction verification purpose." << std::endl;
                }
                file.close();
                
                // íŒŒì¼ í¬ê¸° í™•ì¸ ë° ì¶œë ¥
                auto fsize = fs::file_size("output/data/mass_transactions_large.csv");
                std::cout << "âœ… [Data Service] Generated Size: " << (fsize / 1024 / 1024) << " MB (" << fsize << " bytes)" << std::endl;
            }

            static void generateMassiveLogs() {
                // 100,000ê±´ ë¡œê·¸ ìƒì„±
                const int LOG_COUNT = 100000;
                std::cout << "ğŸ“ [Log Service] Generating " << LOG_COUNT << " log entries..." << std::endl;
                
                fs::create_directories("output/logs");
                std::ofstream log("output/logs/audit_trace_heavy.log");
                
                for(int i=0; i < LOG_COUNT; ++i) {
                    log << "[INFO] " << getCurrentTime() << " | Thread:" << (i%16) 
                        << " | ProcID: " << (9000+i) 
                        << " | Action: Validate_User_Session | Status: SUCCESS | Payload: " 
                        << "Request_data_packet_trace_id_" << i << std::endl;
                }
                log.close();
            }
        };

        class DBPatchManager {
        public:
            bool applyPatch(const std::string& version) {
                std::cout << "\nğŸ—„ï¸ [DB Service] Starting DB Patch to " << version << "..." << std::endl;
                fs::create_directories("output/db");
                
                std::ofstream sql("output/db/migration_script_full.sql");
                sql << "-- Automated Enterprise Migration Script " << version << std::endl;
                // 20,000ê°œ í…Œì´ë¸” ë³€ê²½ ìŠ¤í¬ë¦½íŠ¸
                for(int i=0; i<20000; ++i) {
                    sql << "ALTER TABLE customer_data_shard_" << i << " ADD COLUMN compliance_check_v2 BOOLEAN DEFAULT FALSE;" << std::endl;
                }
                sql.close();
                return true;
            }
        };

        void runUnitTests() {
            std::cout << "\nğŸ§ª [Testing] Running Logic Tests..." << std::endl;
            fs::create_directories("test_dir");
            if(fs::exists("test_dir")) std::cout << "   [PASS] IO Check" << std::endl;
            else exit(1);
            std::cout << "âœ… [Testing] All Tests Passed." << std::endl;
        }

        int main(int argc, char* argv[]) {
            if (argc > 1 && std::string(argv[1]) == "--test") {
                runUnitTests();
                return 0;
            }

            std::cout << "ğŸš€ [Enterprise System] Starting Large Scale Workflow..." << std::endl;
            
            LargePayload::loadDummyData(); // ë°”ì´ë„ˆë¦¬ í¬ê¸° ì¦ê°€ìš©

            BigDataManager::generateMassiveTransactions();
            BigDataManager::generateMassiveLogs();

            DBPatchManager dbMgr;
            dbMgr.applyPatch("v4.0.0_MegaScale");

            std::cout << "\n=============================================" << std::endl;
            std::cout << "ğŸ“¢ [Notice] Official Repository" << std::endl;
            std::cout << "ğŸ”— Follow us at: https://github.com/koreatest12/only-c" << std::endl;
            std::cout << "=============================================\n" << std::endl;

            return 0;
        }
        EOF

    # 3. ì •ì  ì½”ë“œ ë¶„ì„ (ì˜µì…˜ ìœ ì§€)
    - name: Run Static Analysis (Cppcheck)
      if: runner.os == 'Linux'
      run: |
        echo "ğŸ” Running Static Code Analysis..."
        cppcheck --enable=all --inconclusive --force enterprise_main.cpp || true

    # 4. ë¹Œë“œ
    - name: Build Application
      run: |
        echo "ğŸ”¨ Building Application..."
        mkdir -p build
        cd build
        cmake ..
        cmake --build . --config Release

    # 5. í…ŒìŠ¤íŠ¸
    - name: Run Automated Tests
      run: |
        cd build
        if [[ "$RUNNER_OS" == "Windows" ]]; then
          ./Release/enterprise_main.exe --test
        else
          ./enterprise_main --test
        fi

    # 6. ì‹¤í–‰ ë° ëŒ€ëŸ‰ ë¦¬ì†ŒìŠ¤ ìƒì„± (ê²€ì¦ í¬í•¨)
    - name: Run & Generate Heavy Resources
      run: |
        echo "â–¶ï¸ Running Main Application..."
        cd build
        if [[ "$RUNNER_OS" == "Windows" ]]; then
          ./Release/enterprise_main.exe
          cp ./Release/enterprise_main.exe ../server_app.exe
        else
          ./enterprise_main
          cp ./enterprise_main ../server_app_linux
        fi
        
        # ë°ì´í„° í´ë” ì´ë™
        cp -r output ../output_data
        
        # [ê²€ì¦] ìƒì„±ëœ CSV íŒŒì¼ í¬ê¸° í™•ì¸ (ë””ë²„ê¹…ìš©)
        echo "ğŸ“Š Checking Output File Sizes..."
        ls -lh ../output_data/data/ || dir ..\output_data\data\

    # 7. ì—…ë¡œë“œ
    - name: Upload Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: large-build-artifact-${{ matrix.os }}
        path: |
          server_app*
          output_data/
          enterprise_main.cpp
          CMakeLists.txt

  # JOB 2: ë„ì»¤ ë¹Œë“œ
  docker-build:
    name: Dockerize Application
    needs: build-test-generate
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Download Linux Artifacts
        uses: actions/download-artifact@v4
        with:
          name: large-build-artifact-ubuntu-latest
      - name: Create Dockerfile
        run: |
          cat <<EOF > Dockerfile
          FROM ubuntu:22.04
          WORKDIR /app
          COPY server_app_linux /app/server_app
          RUN chmod +x /app/server_app
          CMD ["./server_app"]
          EOF
      - name: Build Docker Image
        run: |
          docker build -t enterprise-server:v${{ github.run_number }} .

  # JOB 3: ë¦´ë¦¬ì¦ˆ
  release-package:
    name: Publish Release
    needs: [build-test-generate, docker-build]
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Download All Artifacts
        uses: actions/download-artifact@v4
      - name: Prepare Release Package
        run: |
          mkdir release_pkg
          cp large-build-artifact-windows-latest/server_app.exe release_pkg/
          cp large-build-artifact-ubuntu-latest/server_app_linux release_pkg/
          cp -r large-build-artifact-ubuntu-latest/output_data release_pkg/large_data_samples
          cd release_pkg
          zip -r ../enterprise_large_v${{ github.run_number }}.zip .
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        if: github.ref == 'refs/heads/main'
        with:
          tag_name: v4.0.${{ github.run_number }}
          name: ğŸš€ Enterprise Scale v4.0.${{ github.run_number }} (10MB+ Data)
          body: |
             ## ğŸ“¦ Enterprise Large Scale Build
             
             1MB ê¸°ì¤€ì„ ì´ˆê³¼í•˜ì—¬ ëŒ€ëŸ‰ì˜ ë°ì´í„° ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ì„ ìˆ˜í–‰í•œ ë¦´ë¦¬ì¦ˆì…ë‹ˆë‹¤.
             
             ### ğŸ“Š Data Scale Report
             - **Transaction CSV:** ~15MB (300,000 Rows)
             - **Audit Logs:** ~8MB (100,000 Entries)
             - **SQL Script:** ~2MB (20,000 Queries)
             
             ### ğŸ“¢ ì»¤ë®¤ë‹ˆí‹°
             ğŸ‘‰ **https://github.com/koreatest12/only-c**
          files: enterprise_large_v${{ github.run_number }}.zip
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
